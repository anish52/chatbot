{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#DATA : https://github.com/suriyadeepan/practical_seq2seq/tree/master/datasets\n",
    "from datasets.twitter import data\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, id_q, id_a = data.load_data(PATH='datasets/twitter/')\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(id_q, id_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7,  106,    3,  616,  214, 1188,  164, 1400, 4744,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 100,    4,  467, 1312,  285,   36,    2, 2187,   10,  842,    2,\n",
       "           1, 1014,    1,  976, 4362,  467, 3840,   16, 1585],\n",
       "       [   1,    1, 1741,    5,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [ 745,  282,  745,    8,  101,   85,  347,  320,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [1185,    4,   40,  327,    7,  162,  888,   53,    4,  437,   15,\n",
       "          44,    7,  125,  207,  220,    5,    0,    0,    0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xseq_len = trainX.shape[-1]\n",
    "yseq_len = trainY.shape[-1]\n",
    "batch_size = 16\n",
    "xvocab_size = len(metadata['idx2w'])\n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seq2seq_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seq2seq_wrapper' from 'C:\\\\Users\\\\N1801369H\\\\Documents\\\\Seq2Seq\\\\seq2seq_wrapper.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(seq2seq_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<log> Building Graph </log>"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = seq2seq_wrapper.Seq2Seq(xseq_len = xseq_len,\n",
    "                               yseq_len = yseq_len,\n",
    "                               xvocab_size = xvocab_size,\n",
    "                               yvocab_size = yvocab_size,\n",
    "                               ckpt_path = 'ckpt/twitter/',\n",
    "                               emb_dim = emb_dim,\n",
    "                               num_layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_gen = data_utils.rand_batch_gen(validX, validY, 256)\n",
    "test_batch_gen = data_utils.rand_batch_gen(testX, testY, 256)\n",
    "train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<log> Training started </log>\n",
      "\n",
      "Model saved to disk at iteration #100\n",
      "val   loss : 3.403190\n",
      "\n",
      "Model saved to disk at iteration #200\n",
      "val   loss : 3.361432\n",
      "\n",
      "Model saved to disk at iteration #300\n",
      "val   loss : 3.298964\n",
      "\n",
      "Model saved to disk at iteration #400\n",
      "val   loss : 3.242165\n",
      "\n",
      "Model saved to disk at iteration #500\n",
      "val   loss : 3.093632\n",
      "Interrupted by user at iteration 580\n"
     ]
    }
   ],
   "source": [
    "sess = model.train(train_batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ckpt/twitter/seq2seq_model.ckpt-500\n"
     ]
    }
   ],
   "source": [
    "sess = model.restore_last_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 20)\n"
     ]
    }
   ],
   "source": [
    "input_ = test_batch_gen.__next__()[0]\n",
    "output = model.predict(sess, input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q : [never mind i found it]; a:[i i i]\n",
      "q : [how much are the touch unk going to be looks like i just spent that money somewhere else instead]; a:[]\n",
      "q : [more hillary right now i was thinking of third party then i remembered that unk halloween episode about aliens]; a:[i i i i]\n",
      "q : [200 more white people have been shot by police this year than blacks stop trying to start a race war]; a:[i]\n"
     ]
    }
   ],
   "source": [
    "replies = []\n",
    "for ii,oi in zip(input_.T, output):\n",
    "    q = data_utils.decode(sequence=ii, lookup=metadata['idx2w'], separator=' ')\n",
    "    decoded = data_utils.decode(sequence=oi, lookup=metadata['idx2w'], separator=' ').split()\n",
    "    if decoded.count('unk') == 0:\n",
    "        if decoded not in replies:\n",
    "            print('q : [{0}]; a:[{1}]'.format(q, ' '.join(decoded)))\n",
    "            replies.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
